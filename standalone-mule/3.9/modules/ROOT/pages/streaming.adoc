= Streaming
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:keywords: mule, esb, studio, streaming, memory, large payload


Streaming supports efficient processing of large data objects such as files, documents, and records by streaming the data through Mule rather than reading the whole thing into memory. Streaming provides the following advantages:

* Allows flows to consume very large messages in an efficient way
* Message payloads are not read into memory
* Simple routing rules based on message metadata are still possible
* You can combine streaming and non-streaming endpoints

== Data Streams Consumption
To understand how data streams are consumed, review the following points:

* Data streams cannot be consumed more than once
+
In the following example, the flow shows the HTTP Listener source that receives a POST method with a body payload to write to the files. The flow writes the first file correctly, while the second file is created with empty content because each component that consumes a stream expects to receive a new stream. After the first File Write operation consumes the stream, the second File Write operation receives an empty stream. Thereby, the second operation has no content to write to a file.
+
.Mule 3 Streaming: Writing a File
image::mruntime-streaming-about-1.png[]
+
In the following example, something similar happens when you try to log the payload after a DataWeave transformation. The HTTP Listener operation receives the payload stream, and then when the stream gets to the Transform Message component, it is available in memory, so the component consumes the stream. After the Transform Message component consumes the content, the second Logger receives an empty stream.
+
.Mule 3 Streaming: Logging a Payload
image::mruntime-streaming-about-2.png[]
+

* Data streams cannot be consumed at the same time
+
In the following example, the flow uses a Scatter-Gather router to split a data stream
and simultaneously log and write the payload to a file. The application get some parts of the stream in the file and the rest on the log because different processor chains can not process the data stream content simultaneously.
+
.Mule 3 Streaming: Consuming Data Streams
image::mruntime-streaming-about-3.png[]
+


== Streaming Transports Connectors and Modules

The following transports, connectors and modules support streaming:

* xref:cxf-module-reference.adoc[CXF]

* xref:database-connector-reference.adoc[Database Connector]
* xref:file-transport-reference.adoc[File] (set the `streaming` attribute to false to access the File object directly)
* xref:ftp-transport-reference.adoc[FTP]
* xref:http-listener-connector.adoc[HTTP Listener] and HTTPS Listener.
* xref:jetty-transport-reference.adoc[Jetty] and xref:jetty-ssl-transport.adoc[Jetty SSL]
* xref:servlet-transport-reference.adoc[Servlet]
* xref:tcp-transport-reference.adoc[TCP]
* xref:udp-transport-reference.adoc[UDP]
* xref:sftp-transport-reference.adoc[SFTP]

== Streaming Transformers and Filters

Many transformers and filters can read input streams, process the contents, and send them on. However, most of these do not process the stream in real time; instead, they read the stream, load it into memory, process it, and then send it on. Therefore, transformers and filters can become a bottleneck in your application if you regularly stream large files.

The following transformers and filters do support true streaming and process the data as streams without loading them into memory first:

* xref:xslt-transformer.adoc[XSLT Transformer]
* xref:xmltoxmlstreamreader-transformer.adoc[XmlToXMLStreamReader Transformer]
* xref:domtoxml-transformer.adoc[DomToOutputHandler transformer] (if the incoming XML format is a SAXSource or XMLStreamReader)
* xref:sxc-module-reference.adoc[SXC filter]
